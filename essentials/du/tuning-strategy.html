<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>5: Tuning strategy | OpenCUI</title>
    <meta name="description" content="Type-based Approach for Chatbot Development">
    <meta name="generator" content="VitePress v1.0.0-rc.44">
    <link rel="preload stylesheet" href="/assets/style.BiTEbHIi.css" as="style">
    
    <script type="module" src="/assets/app.DDWhSvCC.js"></script>
    <link rel="preload" href="/assets/inter-roman-latin.Bu8hRsVA.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/assets/chunks/framework.BGFi9fUZ.js">
    <link rel="modulepreload" href="/assets/chunks/theme.B_5FO281.js">
    <link rel="modulepreload" href="/assets/essentials_du_tuning-strategy.md.D-Hs-Cic.lean.js">
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-L6RW3F0FPM"></script>
    <script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-L6RW3F0FPM");</script>
    <script id="check-dark-mode">document.documentElement.classList.add("dark");</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-5d98c3a5><!--[--><!--]--><!--[--><span tabindex="-1" data-v-0f60ec36></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-0f60ec36> Skip to content </a><!--]--><!----><header class="VPNav" data-v-5d98c3a5 data-v-ae24b3ad><div class="VPNavBar has-sidebar" data-v-ae24b3ad data-v-19c990f1><div class="wrapper" data-v-19c990f1><div class="container" data-v-19c990f1><div class="title" data-v-19c990f1><div class="VPNavBarTitle has-sidebar" data-v-19c990f1 data-v-ab179fa1><a class="title" href="/" data-v-ab179fa1><!--[--><!--]--><!--[--><img class="VPImage logo" src="/images/logo.png" alt data-v-8426fc1a><!--]--><span data-v-ab179fa1>OpenCUI</span><!--[--><!--]--></a></div></div><div class="content" data-v-19c990f1><div class="content-body" data-v-19c990f1><!--[--><!--]--><div class="VPNavBarSearch search" data-v-19c990f1><!----></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-19c990f1 data-v-7f418b0f><span id="main-nav-aria-label" class="visually-hidden" data-v-7f418b0f>Main Navigation</span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink active" href="/essentials/" tabindex="0" data-v-7f418b0f data-v-42ef59de><!--[--><span data-v-42ef59de>Why OpenCUI</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/reference/guide/signingup.html" tabindex="0" data-v-7f418b0f data-v-42ef59de><!--[--><span data-v-42ef59de>Resources</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/pricing/" tabindex="0" data-v-7f418b0f data-v-42ef59de><!--[--><span data-v-42ef59de>Pricing</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/articles/" tabindex="0" data-v-7f418b0f data-v-42ef59de><!--[--><span data-v-42ef59de>Blog</span><!--]--></a><!--]--><!--]--></nav><!----><!----><!----><div class="VPFlyout VPNavBarExtra extra" data-v-19c990f1 data-v-d0bd9dde data-v-b6c34ac9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-b6c34ac9><span class="vpi-more-horizontal icon" data-v-b6c34ac9></span></button><div class="menu" data-v-b6c34ac9><div class="VPMenu" data-v-b6c34ac9 data-v-e7ea1737><!----><!--[--><!--]--></div></div></div><!--[--><!--[--><!--[--><a href="https://build.opencui.io" target="_blank"><button class="button-start"> Get started </button></a><!--]--><!--]--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-19c990f1 data-v-e5dd9c1c><span class="container" data-v-e5dd9c1c><span class="top" data-v-e5dd9c1c></span><span class="middle" data-v-e5dd9c1c></span><span class="bottom" data-v-e5dd9c1c></span></span></button></div></div></div></div><div class="divider" data-v-19c990f1><div class="divider-line" data-v-19c990f1></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-5d98c3a5 data-v-a6f0e41e><div class="container" data-v-a6f0e41e><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-a6f0e41e><span class="vpi-align-left menu-icon" data-v-a6f0e41e></span><span class="menu-text" data-v-a6f0e41e>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-a6f0e41e data-v-d2ecc192><button data-v-d2ecc192>Return to top</button><!----></div></div></div><aside class="VPSidebar" data-v-5d98c3a5 data-v-575e6a36><div class="curtain" data-v-575e6a36></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-575e6a36><span class="visually-hidden" id="sidebar-aria-label" data-v-575e6a36> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="group" data-v-575e6a36><section class="VPSidebarItem level-0 has-active" data-v-575e6a36 data-v-93e7e794><div class="item" role="button" tabindex="0" data-v-93e7e794><div class="indicator" data-v-93e7e794></div><h2 class="text" data-v-93e7e794>Why OpenCUI</h2><!----></div><div class="items" data-v-93e7e794><!--[--><div class="VPSidebarItem level-1 is-link" data-v-93e7e794 data-v-93e7e794><div class="item" data-v-93e7e794><div class="indicator" data-v-93e7e794></div><a class="VPLink link link" href="/essentials/dual-process.html" data-v-93e7e794><!--[--><p class="text" data-v-93e7e794>Dual process</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-93e7e794 data-v-93e7e794><div class="item" data-v-93e7e794><div class="indicator" data-v-93e7e794></div><a class="VPLink link link" href="/essentials/" data-v-93e7e794><!--[--><p class="text" data-v-93e7e794>Schema-guided conversational experiences</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-93e7e794 data-v-93e7e794><div class="item" data-v-93e7e794><div class="indicator" data-v-93e7e794></div><a class="VPLink link link" href="/essentials/cooperative.html" data-v-93e7e794><!--[--><p class="text" data-v-93e7e794>Cooperative principle</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-93e7e794 data-v-93e7e794><div class="item" data-v-93e7e794><div class="indicator" data-v-93e7e794></div><a class="VPLink link link" href="/essentials/5levels-cui.html" data-v-93e7e794><!--[--><p class="text" data-v-93e7e794>5 levels of CUI</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-93e7e794 data-v-93e7e794><div class="item" data-v-93e7e794><div class="indicator" data-v-93e7e794></div><a class="VPLink link link" href="/essentials/architecture.html" data-v-93e7e794><!--[--><p class="text" data-v-93e7e794>Open sourced runtime</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-93e7e794 data-v-93e7e794><div class="item" data-v-93e7e794><div class="indicator" data-v-93e7e794></div><a class="VPLink link link" href="/essentials/document-requirement-for-cui.html" data-v-93e7e794><!--[--><p class="text" data-v-93e7e794>Document CUI design</p><!--]--></a><!----></div><!----></div><section class="VPSidebarItem level-1 has-active" data-v-93e7e794 data-v-93e7e794><div class="item" role="button" tabindex="0" data-v-93e7e794><div class="indicator" data-v-93e7e794></div><h3 class="text" data-v-93e7e794>Dialog Understanding</h3><!----></div><div class="items" data-v-93e7e794><!--[--><div class="VPSidebarItem level-2 is-link" data-v-93e7e794 data-v-93e7e794><div class="item" data-v-93e7e794><div class="indicator" data-v-93e7e794></div><a class="VPLink link link" href="/essentials/du/chatgpt-reset.html" data-v-93e7e794><!--[--><p class="text" data-v-93e7e794>1: A ChatGPT reset</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-93e7e794 data-v-93e7e794><div class="item" data-v-93e7e794><div class="indicator" data-v-93e7e794></div><a class="VPLink link link" href="/essentials/du/du-theory.html" data-v-93e7e794><!--[--><p class="text" data-v-93e7e794>2: Theory</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-93e7e794 data-v-93e7e794><div class="item" data-v-93e7e794><div class="indicator" data-v-93e7e794></div><a class="VPLink link link" href="/essentials/du/towards-zero-shot.html" data-v-93e7e794><!--[--><p class="text" data-v-93e7e794>3: Towards zero shot</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-93e7e794 data-v-93e7e794><div class="item" data-v-93e7e794><div class="indicator" data-v-93e7e794></div><a class="VPLink link link" href="/essentials/du/new-formulations.html" data-v-93e7e794><!--[--><p class="text" data-v-93e7e794>4: New formulations</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-93e7e794 data-v-93e7e794><div class="item" data-v-93e7e794><div class="indicator" data-v-93e7e794></div><a class="VPLink link link" href="/essentials/du/tuning-strategy.html" data-v-93e7e794><!--[--><p class="text" data-v-93e7e794>5: Tuning strategy</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-93e7e794 data-v-93e7e794><div class="item" data-v-93e7e794><div class="indicator" data-v-93e7e794></div><a class="VPLink link link" href="/essentials/du/maintainable-accuracy.html" data-v-93e7e794><!--[--><p class="text" data-v-93e7e794>6: Maintainable accuracy</p><!--]--></a><!----></div><!----></div><!--]--></div></section><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-5d98c3a5 data-v-1428d186><div class="VPDoc has-sidebar has-aside" data-v-1428d186 data-v-39a288b8><!--[--><!--]--><div class="container" data-v-39a288b8><div class="aside" data-v-39a288b8><div class="aside-curtain" data-v-39a288b8></div><div class="aside-container" data-v-39a288b8><div class="aside-content" data-v-39a288b8><div class="VPDocAside" data-v-39a288b8 data-v-3f215769><!--[--><!--]--><!--[--><!--]--><div class="VPDocAsideOutline" role="navigation" data-v-3f215769 data-v-935f8a84><div class="content" data-v-935f8a84><div class="outline-marker" data-v-935f8a84></div><div class="outline-title" role="heading" aria-level="2" data-v-935f8a84>On this page</div><nav aria-labelledby="doc-outline-aria-label" data-v-935f8a84><span class="visually-hidden" id="doc-outline-aria-label" data-v-935f8a84> Table of Contents for current page </span><ul class="VPDocOutlineItem root" data-v-935f8a84 data-v-b933a997><!--[--><!--]--></ul></nav></div></div><!--[--><!--]--><div class="spacer" data-v-3f215769></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-39a288b8><div class="content-container" data-v-39a288b8><!--[--><!--]--><main class="main" data-v-39a288b8><div style="position:relative;" class="vp-doc _essentials_du_tuning-strategy" data-v-39a288b8><div><h1 id="_5-tuning-strategy" tabindex="-1">5: Tuning strategy <a class="header-anchor" href="#_5-tuning-strategy" aria-label="Permalink to &quot;5: Tuning strategy&quot;">​</a></h1><p>Introduced by Vaswani et al. in 2017, the Transformer architecture, a multiple layers of self-attention and feedforward neural networks, has become the standard architecture for training large language models, also known as foundation models.</p><p>The traditional method of training separate models for each NLP task, which necessitates a considerable amount of labeled data for every task, has been swiftly replaced by a multi-stage learning paradigm centered on a universal foundational model. This approach is more production-friendly since it necessitates little or even no labeled data for each new task. We have explained how these few-shot capability comes into being in a <a href="./towards-zero-shot.html">previous blog</a>, let’s take a look how to use foundation model to <a href="./new-formulations.html">solve dialog understanding tasks</a>.</p><h2 id="how-foundation-model-are-trained" tabindex="-1">How foundation model are trained <a class="header-anchor" href="#how-foundation-model-are-trained" aria-label="Permalink to &quot;How foundation model are trained&quot;">​</a></h2><p>Foundation models are typically trained in two stages: pre-training and fine-tuning. During the pre-training stage, a large, high quality corpus of text is compiled from various sources, such as books, articles, and web pages. Using a self-labeling schema that either auto-regressively predicts the next word in a sequence given the previous words in the sequence (like ChatGPT) or auto-associatively predicts the original text given a token sequence with a part of it randomly masked (like Bert), these unlabeled texts can then be used to train a foundation model able to produce high-quality meaning representations of text.</p><p>After pre-trained on a large corpus of text, foundation models can be further fine-tuned on many tasks, such as language translation or text generation. For decoder based model like GPT, fine-tuning is framed as a universal conditional text generation problem. Specifically, labeled data points in the form of (task, input, output) are transformed into labeled data in the form of (prompt, output), where the prompt is a natural language representation of the task and original input. For example: (<em>English to Chinese translation, how are you today, 你今天怎么样</em>) can be reformulated into (<em>translate “how are you today” into Chinese, 你今天怎么样</em>), and (<em>grammar check, “Stalin were a dictator”, “Stalin was a dictator”</em>) into (<em>grammar check: Stalin were a dictator, Stalin was a dictator</em>). Training with reformulated labeled data from many tasks, commonly known instruction fine-tuning or instruction tuning for short, results in a universal model that can treat text input as instructions.</p><p>The result of these expensive training is the weights for model’s parameter. Foundation models consist of three layers, the parameters for each layer are used for different purpose:</p><ol><li><p>Embedding parameters: These are the parameters used to map input tokens (e.g., words, subwords) to high-dimensional vectors called embeddings.</p></li><li><p>Transformer parameters: These are the parameters that define the architecture of the Transformer model, which is used to process the input embeddings and generate representation that summarize the token sequences. The parameter for this layer are typically shared between multiple tasks, and kept frozen during later stage learning.</p></li><li><p>Output parameters: These are the parameters used to generate the output sequence from the final layer of the Transformer. In the case of a language modeling task, the output parameters would typically be the weights of a linear layer that maps the output embeddings back to a vocabulary distribution over the possible output tokens. Clearly different tasks need different output parameters.</p></li></ol><p>Depending on the proportion of parameters that are modified, there are three strategies for solving NLP tasks using existing foundation models. Let’s see what are these, and which one should we use for dialog understanding tasks.</p><h2 id="full-tuning" tabindex="-1">Full-tuning <a class="header-anchor" href="#full-tuning" aria-label="Permalink to &quot;Full-tuning&quot;">​</a></h2><p>Full-tuning, commonly known as fine-tuning, refers to a process where a foundation model is further trained on a new task, using a new dataset with the goal that this later stage tuning can adept the knowledge embedded in the foundation model to this new task.</p><p>In full-tuning, weights are initially initialized based on the foundation model, but all weights can be modified during the tuning process. Full-tuning usually yields the best performance (in terms of accuracy, not speed) among all three tuning strategies. Nevertheless, as models grow in size, storing and deploying a fine-tuned model for each downstream task may become impractical.</p><h2 id="no-tuning-in-context-learning" tabindex="-1">No tuning: in-context learning <a class="header-anchor" href="#no-tuning-in-context-learning" aria-label="Permalink to &quot;No tuning: in-context learning&quot;">​</a></h2><p>The instruction-tuned foundation model, like InstructGPT, demonstrated convincingly that a frozen model can perform different tasks through “in-context” learning. With this approach, a user primes the model for a given task through prompt design or prompt engineering, i.e., hand-crafting a text prompt with a description and sometimes examples of the task. For instance, to predict whether a movie review is positive or not, one could prepend <em>“Is the following movie review positive or negative?”</em> before the actual review to form the prompt, and hopeful get <em>“This movie was amazing!”</em> in return.</p><p>During the in-context learning, all weights are kept frozen. So a single model can serve many tasks. But prompts require careful design, as small change in prompts can result in drastic change in performance. Furthermore, even well-designed prompts can still far under-perform compared to full-tuning. For instance, the performance of a frozen GPT-3 175B parameter model on the <a href="https://super.gluebenchmark.com/" target="_blank" rel="noreferrer">SuperGLUE</a> benchmark is 5 points below a fine-tuned <a href="https://ai.googleblog.com/2020/02/exploring-transfer-learning-with-t5.html" target="_blank" rel="noreferrer">T5 model</a> that uses 800 times fewer parameters. Finally, this paradigm can only use handful of labeled examples, since all examples need to fit into receptive fields of the foundation model (limited to 2k tokens usually). This further limits the performance of this approach.</p><h2 id="delta-tuning" tabindex="-1">Delta-tuning <a class="header-anchor" href="#delta-tuning" aria-label="Permalink to &quot;Delta-tuning&quot;">​</a></h2><p>Only small portion of parameters have their weights changed in this family of methods, and these change can be captured by delta weights. The most popular delta-turning, such as prompt tuning, are additive in nature, where extra trainable parameters are introduced.</p><p>Prompt tuning is an effective last stage learning method that encode input into prompts. But rather than prepending existing tokens (with hard, fixed embedding), we prepend new tokens whose embedding need to be learned (thus also known as soft tokens) to input to form prompt. Conceptually, the soft prompt is trained to captures how to map input to output exemplified by the labeled dataset, performing the same role as a manually written text prompt, but is robustly defined using examples.</p><p>Prompt tuning is an effective last-stage learning method that also encodes input into prompts. Instead of adding existing tokens with a fixed, hard embedding at the beginning of the input, we add new tokens (also known as soft tokens) whose embeddings need to be learned. The soft prompt is trained to capture the mapping from input to output, as encoded in the labeled dataset, fulfilling the same role as a manually created prompt template.</p><p>In prompt tuning, the only weights that get changed are the embedding weight corresponding to these soft tokens. The rest of weight, include transformer weights, output weights, and embedding weights for existing tokens are kept frozen. However, given a reasonable sized foundation model, it is shown that prompt tuning can reach the same performance as fine-tuning, particularly when the foundation model is big enough.</p><p>There many different flavors of delta-tuning. For example, we can have a different output layer for each task, but share the frozen transformer and embedding parameters.</p><h2 id="conclusion" tabindex="-1">Conclusion <a class="header-anchor" href="#conclusion" aria-label="Permalink to &quot;Conclusion&quot;">​</a></h2><p>To build conversational user interface for real world services, we typically need to solve multiple NLP tasks, and often in a incremental fashion.</p><p>Given this circumstance, fine-tuning is clearly not a good option. The memory requirements for serving multiple models, as well as the need to retrain every time there are changes, do not provide a good developer experience.</p><p>While prompt engineering or in-context learning is a useful tool for addressing ad-hoc tasks, its lower accuracy, incapability to incorporate more labeled data, and the quadratic growth in inference cost concerning the number of tokens in prompts make it unsuitable for any practical production scenarios.</p><p>That leaves us with prompt tuning. Prompt tuning can achieve high-level performance that was previously only possible through fine-tuning. Solutions to new tasks can be incrementally developed, and its inference cost is similar to that of fine-tuning, as generally only a few soft tokens are required. Therefore, it should be the default choice when addressing NLP tasks in production, and when feasible, use a multitask fine-tuned foundation model such as <a href="https://arxiv.org/abs/2210.11416" target="_blank" rel="noreferrer">FLAN-T5</a> as starting point. In fact, delta-tuning-based solutions should generally be preferred when possible for the same reasons.</p><p>Reference:</p><ol><li><a href="./towards-zero-shot.html">Towards Zero Shot</a></li><li><a href="./new-formulations.html">New Formulations</a></li><li><a href="https://ai.googleblog.com/2022/02/guiding-frozen-language-models-with.html" target="_blank" rel="noreferrer">Guiding Frozen Language Models with Learned Soft Prompts</a></li><li><a href="https://arxiv.org/abs/2210.11416" target="_blank" rel="noreferrer">Scaling Instruction-Finetuned Language Models</a></li><li><a href="https://arxiv.org/pdf/2203.06904.pdf" target="_blank" rel="noreferrer">Delta Tuning: A Comprehensive Study of Parameter Efficient Methods for Pre-trained Language Models</a></li></ol></div></div></main><footer class="VPDocFooter" data-v-39a288b8 data-v-09de1c0f><!--[--><!--]--><div class="edit-info" data-v-09de1c0f><!----><div class="last-updated" data-v-09de1c0f><p class="VPLastUpdated" data-v-09de1c0f data-v-7e05ebdb>Last updated: <time datetime="2023-05-08T16:10:29.000Z" data-v-7e05ebdb></time></p></div></div><nav class="prev-next" data-v-09de1c0f><div class="pager" data-v-09de1c0f><a class="VPLink link pager-link prev" href="/essentials/du/new-formulations.html" data-v-09de1c0f><!--[--><span class="desc" data-v-09de1c0f>Previous page</span><span class="title" data-v-09de1c0f>4: New formulations</span><!--]--></a></div><div class="pager" data-v-09de1c0f><a class="VPLink link pager-link next" href="/essentials/du/maintainable-accuracy.html" data-v-09de1c0f><!--[--><span class="desc" data-v-09de1c0f>Next page</span><span class="title" data-v-09de1c0f>6: Maintainable accuracy</span><!--]--></a></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><footer class="VPFooter has-sidebar" data-v-5d98c3a5 data-v-e315a0ad><div class="container" data-v-e315a0ad><!----><p class="copyright" data-v-e315a0ad>OpenCUI, Inc © 2024 All rights reserved</p></div></footer><!--[--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"articles_from-schema-to-snippets.md\":\"Bqm-LLWD\",\"articles_reservation-cui-design.md\":\"GsBzMPOM\",\"essentials_architecture.md\":\"0uwtbsVk\",\"essentials_du_tuning-strategy.md\":\"D-Hs-Cic\",\"essentials_index.md\":\"DfHDNCKN\",\"reference_platform_multilingual.md\":\"C0RPVfVl\",\"reference_guide_signingup.md\":\"BwLTIGxS\",\"articles_reservation_readme.md\":\"R3zW1J9x\",\"reference_channels_messenger.md\":\"CkgCldW6\",\"articles_reservation_google-calendar-reservation.md\":\"COMjVEw7\",\"reference_platform_deployment.md\":\"DNOIQjNO\",\"articles_build-reservation-module.md\":\"DikMPx8r\",\"reference_platform_reusability.md\":\"BYlr6WUi\",\"reference_channels_universalmessage.md\":\"Z60cF0dA\",\"reference_platform_testing.md\":\"BTJCu4k9\",\"reference_plugins_components_datepicker_index.md\":\"Dn1tovap\",\"reference_platform_versioncontrol.md\":\"DNYjAH_c\",\"reference_providers_googlesheets.md\":\"R0vlK9eY\",\"reference_plugins_components_datepicker_datepicker-design.md\":\"V3TbNfJK\",\"copilot_overview.md\":\"BQ2Ty8jj\",\"copilot_why-copilot.md\":\"Bx2BoNf7\",\"index.md\":\"Dx7PNWiK\",\"essentials_document-requirement-for-cui.md\":\"FoUaXjeQ\",\"reference_annotations_templateandexemplar.md\":\"B-890xH2\",\"copilot_define-api.md\":\"B6BIwcCO\",\"reference_guide_opencui-flow.md\":\"Br_qIrP-\",\"copilot_build-copilot.md\":\"BDe7eaqz\",\"reference_annotations_transition.md\":\"DQiD4ZSP\",\"essentials_du_chatgpt-reset.md\":\"DoPtvbJY\",\"reference_annotations_valuecheck.md\":\"4CnPuOcd\",\"articles_reuse-reservation-module.md\":\"DDEoUIYM\",\"reference_channels_wpa.md\":\"BcHeeyho\",\"reference_channels_whatsapp.md\":\"DD1fg3rH\",\"reference_conversation-design_design-for-long-tail.md\":\"Fus1TQAq\",\"reference_conversation-design_conversation-design.md\":\"CZfmW0Ig\",\"reference_channels_googlebusiness.md\":\"CTx49kPr\",\"reference_conversation-design_get-started.md\":\"h504Lgeq\",\"reference_conversation-design_gathering-requirements.md\":\"BuQFKBN8\",\"reference_conversation-design_scale-your-design.md\":\"rZ0neX1W\",\"reference_conversation-design_test-and-iterate.md\":\"Cj_Rg9kW\",\"reference_conversation-design_key-use-cases.md\":\"SbdQOyVi\",\"reference_guide_are-you-ready.md\":\"FO4SQ4Xy\",\"reference_glossary.md\":\"BMcvZQTj\",\"reference_guide_build-module.md\":\"kRG2Eu1W\",\"reference_guide_3layers.md\":\"wF7s08hg\",\"reference_guide_build-simple-chatbot.md\":\"CH6GW6eR\",\"reference_guide_build-provider.md\":\"CsBiyHu4\",\"copilot_opencui-sdk.md\":\"DhjY3Cvg\",\"reference_guide_clone-simple-chatbot.md\":\"2K7RME0N\",\"reference_guide_index.md\":\"DS_ALjK4\",\"reference_guide_deploy-to-channel.md\":\"yMMT8Vwy\",\"reference_guide_concepts.md\":\"BAwc2G9N\",\"essentials_du_maintainable-accuracy.md\":\"Dehdy1Q-\",\"reference_annotations_fillstrategy.md\":\"M_dqhXyT\",\"articles_chatbot-development-with-opencui.md\":\"DFvuiTMY\",\"essentials_du_new-formulations.md\":\"a0TyqG9p\",\"reference_annotations_systemcomponent.md\":\"zF0Qksbj\",\"reference_annotations_overview.md\":\"C8gdyqhV\",\"essentials_components.md\":\"dfRxGk3M\",\"essentials_du_towards-zero-shot.md\":\"Cv7ig6Ec\",\"reference_index.md\":\"CLIQClTm\",\"essentials_5levels-cui.md\":\"DleMDsAF\",\"reference_annotations_valuerec.md\":\"6JGtu5kU\",\"policy_privacy.md\":\"CcbqRm4T\",\"essentials_dual-process.md\":\"DcW2aDXJ\",\"articles_reservation_reservation-api.md\":\"wsJnoqQ3\",\"articles_index.md\":\"DpPk6wG0\",\"essentials_cooperative.md\":\"B9xLqsFw\",\"reference_annotations_init.md\":\"BxeIo6qE\",\"reference_annotations_kotlinexpression.md\":\"DW9doe1Z\",\"reference_platform_access.md\":\"J4R-uP_I\",\"reference_providers_native.md\":\"VnpUXQKm\",\"reference_annotations_confirmation.md\":\"vgztIO1a\",\"reference_support_overview.md\":\"B7aUBAjw\",\"pricing_index.md\":\"BSahpB5K\",\"essentials_du_du-theory.md\":\"BZDcMMGZ\",\"reference_providers_extension.md\":\"k6DXQKAI\",\"reference_conversation-design_design-interactions.md\":\"CuhcliE_\",\"essentials_newformulation.md\":\"3x3MgHtw\",\"reference_providers_overview.md\":\"BSVoRzqy\",\"reference_providers_postgrest.md\":\"B-3IpVUb\",\"reference_channels_overview.md\":\"CevogcFh\",\"policy_terms.md\":\"Jy2z_DwH\",\"reference_guide_reuse-component.md\":\"Cykv1b9-\",\"reference_support_chatwoot.md\":\"UGKCbkSC\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"en-US\",\"dir\":\"ltr\",\"title\":\"OpenCUI\",\"description\":\"Type-based Approach for Chatbot Development\",\"base\":\"/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":\"force-dark\",\"themeConfig\":{\"logo\":\"/images/logo.png\",\"outline\":\"deep\",\"nav\":[{\"text\":\"Why OpenCUI\",\"link\":\"/essentials/\",\"activeMatch\":\"/essentials/\"},{\"text\":\"Resources\",\"link\":\"/reference/guide/signingup\",\"activeMatch\":\"/reference/\"},{\"text\":\"Pricing\",\"link\":\"/pricing/\",\"activeMatch\":\"/pricing/\"},{\"text\":\"Blog\",\"link\":\"/articles/\",\"activeMatch\":\"/articles/\"}],\"sidebar\":{\"/essentials/\":[{\"text\":\"Why OpenCUI\",\"items\":[{\"text\":\"Dual process\",\"link\":\"/essentials/dual-process\"},{\"text\":\"Schema-guided conversational experiences\",\"link\":\"/essentials/\"},{\"text\":\"Cooperative principle\",\"link\":\"/essentials/cooperative\"},{\"text\":\"5 levels of CUI\",\"link\":\"/essentials/5levels-cui\"},{\"text\":\"Open sourced runtime\",\"link\":\"/essentials/architecture\"},{\"text\":\"Document CUI design\",\"link\":\"/essentials/document-requirement-for-cui\"},{\"text\":\"Dialog Understanding\",\"items\":[{\"text\":\"1: A ChatGPT reset\",\"link\":\"/essentials/du/chatgpt-reset\"},{\"text\":\"2: Theory\",\"link\":\"/essentials/du/du-theory\"},{\"text\":\"3: Towards zero shot\",\"link\":\"/essentials/du/towards-zero-shot\"},{\"text\":\"4: New formulations\",\"link\":\"/essentials/du/new-formulations\"},{\"text\":\"5: Tuning strategy\",\"link\":\"/essentials/du/tuning-strategy\"},{\"text\":\"6: Maintainable accuracy\",\"link\":\"/essentials/du/maintainable-accuracy\"}]}]}],\"/copilot/\":[{\"text\":\"Copilot\",\"items\":[{\"text\":\"Why copilot\",\"link\":\"/copilot/why-copilot\"},{\"text\":\"Development overview\",\"link\":\"/copilot/overview\"},{\"text\":\"Implement copilot meta API\",\"link\":\"/copilot/define-api\"},{\"text\":\"Build copilot backend\",\"link\":\"/copilot/build-copilot\"},{\"text\":\"Build copilot frontend\",\"link\":\"/copilot/opencui-sdk\"}]}],\"/reference/\":[{\"text\":\"Quickstart\",\"collapsed\":false,\"items\":[{\"text\":\"Get started\",\"link\":\"/reference/guide/signingup\"},{\"text\":\"Clone an echo chatbot\",\"link\":\"/reference/guide/clone-simple-chatbot\"},{\"text\":\"Build an echo chatbot\",\"link\":\"/reference/guide/build-simple-chatbot\"},{\"text\":\"Reuse an hours module\",\"link\":\"/reference/guide/reuse-component\"},{\"text\":\"Build an hours module\",\"link\":\"/reference/guide/build-module\"},{\"text\":\"Build an hours provider\",\"link\":\"/reference/guide/build-provider\"},{\"text\":\"Deploy a chatbot\",\"link\":\"/reference/guide/deploy-to-channel\"},{\"text\":\"Get a team\",\"link\":\"/reference/guide/are-you-ready\"},{\"text\":\"OpenCUI workflow\",\"link\":\"/reference/guide/opencui-flow\"},{\"text\":\"Key concepts\",\"link\":\"/reference/guide/concepts\"}]},{\"text\":\"CUI components\",\"collapsed\":false,\"items\":[{\"text\":\"Overview\",\"link\":\"/reference/annotations/overview\"},{\"text\":\"Fill strategy\",\"link\":\"/reference/annotations/fillstrategy\"},{\"text\":\"Initialization\",\"link\":\"/reference/annotations/init\"},{\"text\":\"Value recommendation\",\"link\":\"/reference/annotations/valuerec\"},{\"text\":\"Value check\",\"link\":\"/reference/annotations/valuecheck\"},{\"text\":\"Confirmation\",\"link\":\"/reference/annotations/confirmation\"},{\"text\":\"State transition\",\"link\":\"/reference/annotations/transition\"},{\"text\":\"System CUI Components\",\"link\":\"/reference/annotations/systemcomponent\"}]},{\"text\":\"Providers\",\"collapsed\":false,\"items\":[{\"text\":\"Overview\",\"link\":\"/reference/providers/overview\"},{\"text\":\"PostgreSQL provider\",\"link\":\"/reference/providers/postgrest\"}]},{\"text\":\"Channels\",\"collapsed\":false,\"items\":[{\"text\":\"Overview\",\"link\":\"/reference/channels/overview\"},{\"text\":\"Universal Channel\",\"link\":\"/reference/channels/universalmessage\"},{\"text\":\"Google Business Message\",\"link\":\"/reference/channels/googlebusiness\"},{\"text\":\"Messenger\",\"link\":\"/reference/channels/messenger\"},{\"text\":\"WhatsApp\",\"link\":\"/reference/channels/whatsapp\"}]},{\"text\":\"Supports\",\"collapsed\":false,\"items\":[{\"text\":\"Overview\",\"link\":\"/reference/support/overview\"},{\"text\":\"Chatwoot\",\"link\":\"/reference/support/Chatwoot\"}]},{\"text\":\"Extension\",\"collapsed\":false,\"items\":[{\"text\":\"Extensions\",\"link\":\"/reference/providers/extension\"},{\"text\":\"Native provider\",\"link\":\"/reference/providers/native\"}]},{\"text\":\"Conversation Design\",\"collapsed\":false,\"items\":[{\"text\":\"Overview\",\"link\":\"/reference/conversation-design/conversation-design\"},{\"text\":\"Get started\",\"link\":\"/reference/conversation-design/get-started\"},{\"text\":\"Gathering requirements\",\"link\":\"/reference/conversation-design/gathering-requirements\"},{\"text\":\"Design interactions\",\"link\":\"/reference/conversation-design/design-interactions\"},{\"text\":\"Key use cases\",\"link\":\"/reference/conversation-design/key-use-cases\"},{\"text\":\"Test and iterate\",\"link\":\"/reference/conversation-design/test-and-iterate\"},{\"text\":\"Design for the long tail\",\"link\":\"/reference/conversation-design/design-for-long-tail\"},{\"text\":\"Scale your design\",\"link\":\"/reference/conversation-design/scale-your-design\"}]},{\"text\":\"Platform\",\"collapsed\":false,\"items\":[{\"text\":\"Multilingual\",\"link\":\"/reference/platform/multilingual\"},{\"text\":\"Testing\",\"link\":\"/reference/platform/testing\"},{\"text\":\"Deployment\",\"link\":\"/reference/platform/deployment\"},{\"text\":\"Version control\",\"link\":\"/reference/platform/versioncontrol\"},{\"text\":\"Access control\",\"link\":\"/reference/platform/access\"},{\"text\":\"Reusability\",\"link\":\"/reference/platform/reusability\"}]},{\"text\":\"Glossary\",\"link\":\"/reference/glossary\"}],\"/policy/\":[{\"text\":\"Terms of service\",\"link\":\"/policy/terms\"},{\"text\":\"Privacy policy\",\"link\":\"/policy/privacy\"}]},\"footer\":{\"copyright\":\"OpenCUI, Inc © 2024 All rights reserved\"}},\"locales\":{},\"scrollOffset\":134,\"cleanUrls\":false}");</script>
    
  </body>
</html>